{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f416c001",
   "metadata": {},
   "source": [
    "## Microsoft Agent Framework\n",
    "[Microsoft Agent Framework](https://github.com/microsoft/agent-framework) is an open-source development kit for building AI agents and multi-agent workflows for .NET and Python. It brings together and extends ideas from [Semantic Kernel](https://github.com/microsoft/semantic-kernel) and [AutoGen](https://github.com/microsoft/autogen) projects, combining their strengths while adding new capabilities.\n",
    "Built by the same teams, it is the unified foundation for building AI agents going forward.\n",
    "\n",
    "Agent Framework offers two primary categories of capabilities:\n",
    "\n",
    "- [AI agents](https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview#ai-agents): Individual agents that use LLMs to process user inputs, call tools and MCP servers to perform actions, and generate responses. Agents support model providers including Azure OpenAI, OpenAI, and Azure AI.\n",
    "- [Workflows](https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview#workflows): Graph-based workflows that connect multiple agents and functions to perform complex, multi-step tasks. Workflows support type-based routing, nesting, checkpointing, and request/response patterns for human-in-the-loop scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a608",
   "metadata": {},
   "source": [
    "### Agents\n",
    "All agents are derived from a common base class, `AIAgent`, which provides a consistent interface for all agent types. \n",
    "\n",
    "Agent Framework supports many different types of agents. This tutorial shows you how to create and run an agent with Agent Framework based on the Azure OpenAI Chat Completion service, but all other agent types are run in the same way.\n",
    "\n",
    "\n",
    "These agents support a wide range of functionality out of the box:\n",
    "\n",
    "1. Function calling\n",
    "2. Multi-turn conversations with local chat history management or service provided chat history management\n",
    "3. Custom service provided tools (e.g. MCP, Code Execution)\n",
    "4. Structured output\n",
    "5. Streaming responses\n",
    "\n",
    "\n",
    "For more information on other agent types and how to construct them, see the [MAF Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876825f9",
   "metadata": {},
   "source": [
    "### Our first Agent\n",
    "\n",
    "Now, let's build an single agent to get started. First, create a chat client for communicating with Azure OpenAI:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT - The endpoint it should talk to by default\n",
    "AZURE_OPENAI_API_KEY - The API Key it should use\n",
    "AZURE_OPENAI_API_VERSION - Inference API version it should use per default\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME - Model deployment name it should use per default\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME - Embedding deployment name it should use per default\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Create the client using API key\n",
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=deployment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c6a59",
   "metadata": {},
   "source": [
    "To create an agent, simply construct a `ChatAgent` using the chat client implementation of your choice:\n",
    "\n",
    "```python\n",
    "simple_agent = ChatAgent(\n",
    "\tchat_client = AzureOpenAIChatClient(),\n",
    "\tinstructions = \"You are a helpful assistant\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "Below is an example of using a convenience method `create_agent()` for creating a ChatAgent tied to our Azure OpenAI Chat Completion client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b71d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727c650",
   "metadata": {},
   "source": [
    "### Running the agent \n",
    "To run the agent, call the `run` method on the agent instance, providing the user input. The agent will return a response object, and accessing the `.text` property provides the text result from the agent.\n",
    "\n",
    "To run the agent with streaming, call the `run_stream` method on the agent instance, providing the user input.\n",
    "\n",
    "The agent will stream a list of update objects, and accessing the `.text` property on each update object provides the part of the text result contained in that update.\n",
    "\n",
    "Python agents support passing keyword arguments to customize each run. The specific options available depend on the agent type, but `ChatAgent` supports many chat client parameters that can be passed to both `run` and `run_stream` methods. Common options include `max_tokens`, `temperature`, `model`, `tools`, `response_format`.\n",
    "\n",
    "Please note that we do not have an chat history, so every message we send to the agent is treated as a new conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ee93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular run\n",
    "response = await simple_agent.run(\"What's the capital of Latvia?\")\n",
    "print(\"Full response:\", response.text)\n",
    "\n",
    "# Streaming run\n",
    "print(\"\\nStreaming response:\")\n",
    "async for chunk in simple_agent.run_stream(\"Explain why having a capital for a country is important in two short sentences.\", \n",
    "        max_tokens=30):\n",
    "    # Each chunk is a partial piece of the model's output\n",
    "    if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91396922",
   "metadata": {},
   "source": [
    "### Threading and Multi-Turn Conversations\n",
    "\n",
    "So far, our agents are stateless and do not maintain any state internally between calls. If you ask them a follow up question, they would have no reference to the prior conversation.\n",
    "\n",
    "To have a multi-turn conversation with an agent, you need to create an object to hold the conversation state and pass this object to the agent when running it.\n",
    "\n",
    "An `AgentThread` maintains the conversation state and message history for an agent interaction. It can either use a service-managed thread (via service_thread_id) or a local message store (via message_store), but not both.\n",
    "\n",
    "To create the conversation state object, call the `get_new_thread()` method on the agent instance. In case you do not provide an `AgentThread`, the agent will create a throwaway underlying thread which will be discarded after the run.\n",
    "\n",
    "You can then pass this thread object to the `run` or `run_stream` methods on the agent instance, along with the user input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29461187",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")\n",
    "\n",
    "# create a thread for the agent instance:\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Hello!\",\n",
    "    \"Which country has Paris as the capital?\",\n",
    "    \"What are its neighbouring countries? Give a short one-liner list, please.\"\n",
    "]\n",
    "\n",
    "# Loop through user messages and maintain context\n",
    "for user_message in user_messages:\n",
    "    print(\"*** User:\", user_message)\n",
    "    \n",
    "    # get response from the agent, passing the same thread\n",
    "    response = await agent.run(user_message, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n",
    "\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print the final conversation history from the thread\n",
    "messages = await thread.message_store.list_messages()\n",
    "for msg in messages:\n",
    "    print(f\"[{msg.role}] {msg.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05405608",
   "metadata": {},
   "source": [
    "Learn more about threading, custom message stores and serialization [here](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python) and [here](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/persisted-conversation?pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24686014",
   "metadata": {},
   "source": [
    "### Single agent with multiple conversations\n",
    "\n",
    "It is possible to have multiple, independent conversations with the same agent instance by creating multiple `AgentThread` objects. These threads can then be used to maintain separate conversation states for each conversation. The conversations will be fully independent of each other, since the agent does not maintain any state internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996457e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = agent.get_new_thread()\n",
    "thread2 = agent.get_new_thread()\n",
    "\n",
    "# First messages for each thread\n",
    "result1 = await agent.run(\"Suggest 1 key attraction for Paris trip. Keep it brief.\", thread=thread1)\n",
    "print(\"Thread 1:\", result1.text)\n",
    "\n",
    "result2 = await agent.run(\"Suggest 1 key attraction for Tokyo trip. Keep it brief.\", thread=thread2)\n",
    "print(\"Thread 2:\", result2.text)\n",
    "\n",
    "# Continue each conversation independently\n",
    "result3 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread1\n",
    ")\n",
    "print(\"Thread 1:\", result3.text)\n",
    "\n",
    "result4 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread2\n",
    ")\n",
    "print(\"Thread 2:\", result4.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8a5d1",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> See the solution</summary>\n",
    "\n",
    "```python\n",
    "thread1 = agent.get_new_thread()\n",
    "thread2 = agent.get_new_thread()\n",
    "\n",
    "# First messages for each thread\n",
    "result1 = await agent.run(\"Suggest 1 key attraction for Paris trip. Keep it brief.\", thread=thread1)\n",
    "print(\"Thread 1:\", result1.text)\n",
    "\n",
    "result2 = await agent.run(\"Suggest 1 key attraction for Tokyo trip. Keep it brief.\", thread=thread2)\n",
    "print(\"Thread 2:\", result2.text)\n",
    "\n",
    "# Continue each conversation independently\n",
    "result3 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread1\n",
    ")\n",
    "print(\"Thread 1:\", result3.text)\n",
    "\n",
    "result4 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread2\n",
    ")\n",
    "print(\"Thread 2:\", result4.text)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7889804",
   "metadata": {},
   "source": [
    "### Agent Function Tools\n",
    "Tooling support may vary considerably between different agent types. Some agents may allow developers to customize the agent at construction time by providing external function tools or by choosing to activate specific built-in tools that are supported by the agent. \n",
    "\n",
    "The `ChatAgent` is an agent class that can be used to build agentic capabilities on top of any inference service. It comes with support for:\n",
    "\n",
    "1. Using your own function tools with the agent\n",
    "2. Using built-in tools that the underlying service may support\n",
    "3. Using hosted tools like web search and MCP (Model Context Protocol) servers\n",
    "\n",
    "Let's try to provide function tools during agent construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb24b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from datetime import datetime\n",
    "\n",
    "def get_time() -> str:\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Sample function tool\n",
    "def get_weather(\n",
    "    location: Annotated[str, \"The location to get the weather for.\"],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C.\"\n",
    "\n",
    "# Agent with agent-level tool available  for all runs\n",
    "agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(),\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    tools=[get_time] \n",
    ")\n",
    "\n",
    "# This run has access to both get_time (agent-level) and get_weather (run-level)\n",
    "result = await agent.run(\n",
    "    \"What's the weather and time in New York?\",\n",
    "    tools=[get_weather]  # Additional tool for this run\n",
    ")\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb93d5",
   "metadata": {},
   "source": [
    "You can also use the `ai_function` decorator to explicitly define function name and description for LLM readability and behaviour:\n",
    "```python\n",
    "from agent_framework import ai_function\n",
    "\n",
    "@ai_function(name=\"weather_tool\", description=\"Retrieves weather information\")\n",
    "# your function here:\n",
    "def get_weather(...)\n",
    "\n",
    "```\n",
    "\n",
    "If you don't use a decorator, the framework will use function name and docstring by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7e4d9",
   "metadata": {},
   "source": [
    "You can also create a class that contains **multiple function tools** as methods.\n",
    "\n",
    " In the following example, let's try to create an agent that works as a note taking assistant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "class NotesTools:\n",
    "    def __init__(self):\n",
    "        self.notes = []  # Store notes as (timestamp, note)\n",
    "\n",
    "    def list_notes(self) -> Annotated[List[Tuple[str, str]], \"Returns all notes as (timestamp, note).\"]:\n",
    "        \"\"\"Return all notes with their timestamps.\"\"\"\n",
    "        if not self.notes:\n",
    "            return \"No notes available.\"\n",
    "        return self.notes\n",
    "\n",
    "    def write_note(\n",
    "        self,\n",
    "        note: Annotated[str, \"The note message to save.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Save a note with the current timestamp.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.notes.append((timestamp, note))\n",
    "        return f\"Note added at {timestamp}.\"\n",
    "\n",
    "    \n",
    "# create tools instance\n",
    "tools = NotesTools()\n",
    "\n",
    "# create agent with tools\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are an assistant that logs, stores notes and shows them. Everything i send is a note i want you to log in my notebook.\",\n",
    "    tools=[tools.write_note, tools.list_notes]\n",
    ")\n",
    "\n",
    "# create a thread for multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Find new soup recipes.\",\n",
    "    \"Find new project opportunities at university.\",\n",
    "    \"Don't forget to call Jess to say happy birthday.\",\n",
    "    \"Can you list all my notes?\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1197ca5",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>See the solution</summary>\n",
    "\n",
    "```python\n",
    "from typing import Annotated, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "class NotesTools:\n",
    "    def __init__(self):\n",
    "        self.notes = []  # Store notes as (timestamp, note)\n",
    "\n",
    "    def list_notes(self) -> Annotated[List[Tuple[str, str]], \"Returns all notes as (timestamp, note).\"]:\n",
    "        \"\"\"Return all notes with their timestamps.\"\"\"\n",
    "        if not self.notes:\n",
    "            return \"No notes available.\"\n",
    "        return self.notes\n",
    "\n",
    "    def write_note(\n",
    "        self,\n",
    "        note: Annotated[str, \"The note message to save.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Save a note with the current timestamp.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.notes.append((timestamp, note))\n",
    "        return f\"Note added at {timestamp}.\"\n",
    "\n",
    "    \n",
    "# create tools instance\n",
    "tools = NotesTools()\n",
    "\n",
    "# create agent with tools\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are an assistant that logs, stores notes and shows them. Everything i send is a note i want you to log in my notebook.\",\n",
    "    tools=[tools.write_note, tools.list_notes]\n",
    ")\n",
    "\n",
    "# create a thread for multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Find new soup recipes.\",\n",
    "    \"Find new project opportunities at university.\",\n",
    "    \"Don't forget to call Jess to say happy birthday.\",\n",
    "    \"Can you list all my notes?\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n",
    "\n",
    "```    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7476e",
   "metadata": {},
   "source": [
    "## Exercise - Implement an Agent with Function Tools\n",
    "\n",
    "In this exercise, you'll create an agent that manages tasks with priorities and deadlines. This will help you understand how to create and expose function tools to an agent and run a multi-turn conversation.\n",
    "\n",
    "#### Task:\n",
    "1. Create a `TaskManagerTools` class with the following functions:\n",
    "    - `add_task(name, priority, deadline)` - Adds a new task with a description, priority (high, medium, low), and deadline in DD-MM format.\n",
    "    - `list_tasks()` - Returns all tasks with their details.\n",
    "    - `filter_by_priority(priority)` - Returns tasks that match the given priority.\n",
    "\n",
    "2. Annotate parameters with `Annotated` to provide descriptions for better LLM understanding.\n",
    "3. Create an agent with clear instructions and register function tools\n",
    "4. Test the agent with a multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489005db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TaskManagerTools:\n",
    "    def __init__(self):\n",
    "        self.tasks: List[Dict[str, str]] = []  # expected list of dicts, each task: {\"name\": str, \"priority\": str, \"deadline\": str}\n",
    "\n",
    "    def add_task(\n",
    "        self,\n",
    "        name: Annotated[str, \"The task description.\"],\n",
    "        priority: Annotated[str, \"Priority level: high, medium, low.\"],\n",
    "        deadline: Annotated[str, \"Deadline in format like 'September 30' or '30.10'.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Add a new task with priority and deadline (stored as DD-MM).\"\"\"\n",
    "        deadline_str = deadline  # Default to raw input\n",
    "        try:\n",
    "            # Try parsing \"September 30\" or \"30.10\"\n",
    "            if \".\" in deadline:  # Format like 30.10\n",
    "                parsed_date = datetime.strptime(deadline, \"%d-%m\")\n",
    "            else:  # Format like September 30\n",
    "                parsed_date = datetime.strptime(deadline, \"%B %d\")\n",
    "            deadline_str = parsed_date.strftime(\"%d-%m\")\n",
    "        except ValueError:\n",
    "            # If parsing fails, keep raw input\n",
    "            pass\n",
    "\n",
    "        self.tasks.append({\"name\": name, \"priority\": priority, \"deadline\": deadline_str})\n",
    "        return f\"Task '{name}' added with priority {priority} and deadline {deadline_str}.\"\n",
    "\n",
    "    def list_tasks(self) -> Annotated[List[Dict[str, str]], \"Returns all tasks with details.\"]:\n",
    "        \"\"\"List all tasks.\"\"\"\n",
    "        return self.tasks if self.tasks else \"No tasks available.\"\n",
    "\n",
    "    def filter_by_priority(\n",
    "        self,\n",
    "        priority: Annotated[str, \"Priority level to filter: high, medium, low.\"],\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return tasks matching the given priority.\"\"\"\n",
    "        filtered = [task for task in self.tasks if task[\"priority\"] == priority]\n",
    "        return filtered if filtered else f\"No tasks with priority {priority}.\"\n",
    "\n",
    "\n",
    "# Create agent with tools\n",
    "tools = TaskManagerTools()\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful and precise assistant that manages tasks with priorities and deadlines.\",\n",
    "    tools=[tools.add_task, tools.list_tasks, tools.filter_by_priority]\n",
    ")\n",
    "\n",
    "# Multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "user_messages = [\n",
    "    \"Add a task to prepare workshop slides, high priority by 30.10\",\n",
    "    \"Send invites by december 30th\",\n",
    "    \"I need to send an email to Kate by nov 4\",\n",
    "    \"List all tasks.\",\n",
    "    \"Show me tasks with low priority.\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5e4dc",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>See the solution</summary>\n",
    "\n",
    "```python\n",
    "from typing import Annotated, List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TaskManagerTools:\n",
    "    def __init__(self):\n",
    "        self.tasks: List[Dict[str, str]] = []  # expected list of dicts, each task: {\"name\": str, \"priority\": str, \"deadline\": str}\n",
    "\n",
    "    def add_task(\n",
    "        self,\n",
    "        name: Annotated[str, \"The task description.\"],\n",
    "        priority: Annotated[str, \"Priority level: high, medium, low.\"],\n",
    "        deadline: Annotated[str, \"Deadline in format like 'September 30' or '30.10'.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Add a new task with priority and deadline (stored as DD-MM).\"\"\"\n",
    "        deadline_str = deadline  # Default to raw input\n",
    "        try:\n",
    "            # Try parsing \"September 30\" or \"30.10\"\n",
    "            if \".\" in deadline:  # Format like 30.10\n",
    "                parsed_date = datetime.strptime(deadline, \"%d-%m\")\n",
    "            else:  # Format like September 30\n",
    "                parsed_date = datetime.strptime(deadline, \"%B %d\")\n",
    "            deadline_str = parsed_date.strftime(\"%d-%m\")\n",
    "        except ValueError:\n",
    "            # If parsing fails, keep raw input\n",
    "            pass\n",
    "\n",
    "        self.tasks.append({\"name\": name, \"priority\": priority, \"deadline\": deadline_str})\n",
    "        return f\"Task '{name}' added with priority {priority} and deadline {deadline_str}.\"\n",
    "\n",
    "    def list_tasks(self) -> Annotated[List[Dict[str, str]], \"Returns all tasks with details.\"]:\n",
    "        \"\"\"List all tasks.\"\"\"\n",
    "        return self.tasks if self.tasks else \"No tasks available.\"\n",
    "\n",
    "    def filter_by_priority(\n",
    "        self,\n",
    "        priority: Annotated[str, \"Priority level to filter: high, medium, low.\"],\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return tasks matching the given priority.\"\"\"\n",
    "        filtered = [task for task in self.tasks if task[\"priority\"] == priority]\n",
    "        return filtered if filtered else f\"No tasks with priority {priority}.\"\n",
    "\n",
    "\n",
    "# Create agent with tools\n",
    "tools = TaskManagerTools()\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful and precise assistant that manages tasks with priorities and deadlines.\",\n",
    "    tools=[tools.add_task, tools.list_tasks, tools.filter_by_priority]\n",
    ")\n",
    "\n",
    "# Multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "user_messages = [\n",
    "    \"Add a task to prepare workshop slides, high priority by 30.10\",\n",
    "    \"Send invites by december 30th\",\n",
    "    \"I need to send an email to Kate by nov 4\",\n",
    "    \"List all tasks.\",\n",
    "    \"Show me tasks with low priority.\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aff74b",
   "metadata": {},
   "source": [
    "### Agent Middleware\n",
    "\n",
    "Middleware in the Agent Framework provides a powerful way to intercept, modify, and enhance agent interactions at various stages of execution. You can use middleware to implement cross-cutting concerns such as logging, security validation, error handling, and result transformation without modifying your core agent or function logic.\n",
    "\n",
    "Function-based middleware is the simplest way to implement middleware using async functions. This approach is ideal for stateless operations and provides a lightweight solution for common middleware scenarios.\n",
    "\n",
    "1. Agent Middleware\n",
    "2. Function Middleware\n",
    "3. Chat Middleware\n",
    "\n",
    "The following example demonstrates how middleware can be used to log execution details at a function (logs when a tool function is called and completed) and agent (logs before and after the entire agent run) levels. This gives you visibility and control over the agent’s behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from agent_framework import FunctionInvocationContext\n",
    "from typing import Callable, Awaitable\n",
    "from agent_framework import agent_middleware\n",
    "\n",
    "def get_time():\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# middleware hooks onto function invocation events\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Middleware that logs function execution.\"\"\"\n",
    "    print(f\"[Function] Calling {context.function.name}\")\n",
    "\n",
    "    await next(context) # executes the actual function or any next MW\n",
    "\n",
    "    print(f\"[Function] {context.function.name} completed\")\n",
    "    print(f\"[Function] Result: {context.result}\")\n",
    "\n",
    "\n",
    "# agent-level MW is applied to the entire agent run\n",
    "@agent_middleware  # Explicitly marks as agent middleware\n",
    "async def logging_agent_middleware(context, next):    # don't need to explicitly declare type annotations\n",
    "    \"\"\"Agent middleware with decorator - types are inferred.\"\"\"\n",
    "    print(f\"[Agent] BEFORE execution\")\n",
    "    await next(context)     # executes the agent logic\n",
    "    print(f\"[Agent] AFTER execution | Agent output: {context.result}\")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    name=\"TimeAgent\",\n",
    "    instructions=\"You can tell the current time.\",\n",
    "    tools=[get_time],    \n",
    "    middleware=[logging_function_middleware, logging_agent_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\"What time is it?\")\n",
    "print(\"Final response: \", result.text)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "# the following response doesn't invoke get_time() so logging_function MW won't fire\n",
    "result = await agent.run(\n",
    "    \"Can you help?\"\n",
    ")\n",
    "\n",
    "print(\"Final response: \", result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651f7e6",
   "metadata": {},
   "source": [
    "### Example: Controlling Light States with an Agent\n",
    "This example shows how an agent can perform actions on light states directly using a custom tool class. We define a `LightsTools` class that manages a list of lights, each represented by a `LightModel` typed dictionary. \n",
    "\n",
    "The agent can:\n",
    "- List all lights and their current states.\n",
    "- Get the state of a specific light by ID.\n",
    "- Change the state (on/off, brightness, color) of a light.\n",
    "\n",
    "By exposing these methods as tools, the agent can interact with and modify the environment dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aee3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Optional\n",
    "\n",
    "# Define a typed dictionary for light properties\n",
    "class LightModel(TypedDict):\n",
    "    id: int\n",
    "    name: str\n",
    "    is_on: bool | None\n",
    "    brightness: int | None\n",
    "    hex: str | None\n",
    "\n",
    "# Tool class for managing lights\n",
    "class LightsTools:\n",
    "    def __init__(self, lights: list[LightModel]): # stores a list of lights in self.lights\n",
    "        self.lights = lights\n",
    "\n",
    "    def get_lights(self) -> List[LightModel]:                \n",
    "        \"\"\"Get a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    def get_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"] #  Annotated adds documentation for LLMs\n",
    "    ) -> Optional[LightModel]:\n",
    "        \"\"\"Get the state of a particular light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                return light\n",
    "        return None\n",
    "    \n",
    "    def change_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"], new_state: LightModel\n",
    "    ) -> dict:\n",
    "        \"\"\"Change the state of the light and returns previous/current info.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                previous = light.copy()  # snapshot before change\n",
    "                light[\"is_on\"] = new_state.get(\"is_on\", light[\"is_on\"])\n",
    "                light[\"brightness\"] = new_state.get(\"brightness\", light[\"brightness\"])\n",
    "                light[\"hex\"] = new_state.get(\"hex\", light[\"hex\"])\n",
    "                return {\n",
    "                    \"previous\": previous,\n",
    "                    \"current\": light\n",
    "                }\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16198173",
   "metadata": {},
   "source": [
    "Now that we have the `LightsTools` class defined, we need to provide initial data for the lights and create an instance of the class. This instance will hold the current state of all lights and expose methods that the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = [\n",
    "    {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False, \"brightness\": 100, \"hex\": \"FF0000\"},\n",
    "    {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False, \"brightness\": 50, \"hex\": \"00FF00\"},\n",
    "    {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True, \"brightness\": 75, \"hex\": \"0000FF\"},\n",
    "]\n",
    "\n",
    "# data to instantiate a class and pass methods as tools\n",
    "tools = LightsTools(lights=lights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72325f0",
   "metadata": {},
   "source": [
    "Now that we have defined the `LightsTools` class and instantiated it with initial light data, let's create the agent, attach the tools, and run a command to control the lights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ebc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    \n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn on all lamps\",\n",
    "    )\n",
    "\n",
    "print(result)\n",
    "print(\"Final data:\", tools.lights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a948d9",
   "metadata": {},
   "source": [
    "### Exercise - Add Your Own Middleware to an Agent\n",
    "In the following exercise, we'll be adding middleware for easier debugging and understanding of agent behavior, because currently we can't see anything besides agent's response.\n",
    "We'll add function middleware which intercepts function calls within agents, chat middleware for OpenAI usage logging and agent-level middleware which is persistent across all runs for tool call counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec56a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from agent_framework import function_middleware, agent_middleware, chat_middleware\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@agent_middleware       # decorator allows to skip type annotations like AgentRunContext\n",
    "async def agent_middleware(context,next                           \n",
    ") -> None:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    logger.info(f\"[Agent] Starting execution\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    # Calculate total duration\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Agent] Agent run completed in {duration:.4f}s\")\n",
    "\n",
    "@chat_middleware \n",
    "async def chat_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Chat] Sending {len(context.messages)} messages to AI\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    logger.info(\"[Chat] Response received\")\n",
    "\n",
    "@function_middleware        \n",
    "async def function_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Function] Calling - {context.function.name} | Args: {context.arguments}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Function] Completed \\\"{context.function.name}\\\" in {duration:.6f}s | Result: {context.result}\")\n",
    "\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state],\n",
    "    middleware=[agent_middleware, chat_middleware, function_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn off all lights and give me their final state\"\n",
    "    )\n",
    "\n",
    "print(\"Assistant >\" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a52d8",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>See the solution</summary>\n",
    "\n",
    "```python\n",
    "import logging\n",
    "import time\n",
    "from agent_framework import function_middleware, agent_middleware, chat_middleware\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@agent_middleware       # decorator allows to skip type annotations like AgentRunContext\n",
    "async def agent_middleware(context,next                           \n",
    ") -> None:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    logger.info(f\"[Agent] Starting execution\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    # Calculate total duration\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Agent] Agent run completed in {duration:.4f}s\")\n",
    "\n",
    "@chat_middleware \n",
    "async def chat_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Chat] Sending {len(context.messages)} messages to AI\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    logger.info(\"[Chat] Response received\")\n",
    "\n",
    "@function_middleware        \n",
    "async def function_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Function] Calling - {context.function.name} | Args: {context.arguments}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Function] Completed \\\"{context.function.name}\\\" in {duration:.6f}s | Result: {context.result}\")\n",
    "\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state],\n",
    "    middleware=[agent_middleware, chat_middleware, function_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn off all lights and give me their final state\"\n",
    "    )\n",
    "\n",
    "print(\"Assistant >\" + str(result))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70105f17",
   "metadata": {},
   "source": [
    "### Exercise: Create Your Own Function Tools\n",
    "\n",
    "Now it's your turn to create a custom plugin and use it with an agent. Your plugin could simulate a database lookup, a translation service, or any other useful functionality.\n",
    "\n",
    "Your task:\n",
    "1. Create a custom plugin class with at least two kernel functions\n",
    "2. Add the plugin to the kernel\n",
    "3. Create an agent that uses your plugin\n",
    "4. Test the agent with appropriate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example solution\n",
    "from typing import Annotated\n",
    "\n",
    "class TranslationTool:\n",
    "    \"\"\"A tool that simulates a language translation service.\"\"\"\n",
    "    \n",
    "    # Dictionary of supported languages and their codes\n",
    "    _supported_languages = {\n",
    "        \"english\": \"en\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"french\": \"fr\",\n",
    "        \"german\": \"de\",\n",
    "        \"italian\": \"it\",\n",
    "        \"japanese\": \"ja\",\n",
    "        \"chinese\": \"zh\",\n",
    "    }\n",
    "    \n",
    "    # Simple translation dictionary for common phrases (in a real plugin, this would use an API)\n",
    "    _translations = {\n",
    "        \"hello\": {\n",
    "            \"es\": \"hola\",\n",
    "            \"fr\": \"bonjour\",\n",
    "            \"de\": \"hallo\",\n",
    "            \"it\": \"ciao\",\n",
    "            \"ja\": \"こんにちは\",\n",
    "            \"zh\": \"你好\"\n",
    "        },\n",
    "        \"goodbye\": {\n",
    "            \"es\": \"adiós\",\n",
    "            \"fr\": \"au revoir\",\n",
    "            \"de\": \"auf wiedersehen\",\n",
    "            \"it\": \"arrivederci\",\n",
    "            \"ja\": \"さようなら\",\n",
    "            \"zh\": \"再见\"\n",
    "        },\n",
    "        \"thank you\": {\n",
    "            \"es\": \"gracias\",\n",
    "            \"fr\": \"merci\",\n",
    "            \"de\": \"danke\",\n",
    "            \"it\": \"grazie\",\n",
    "            \"ja\": \"ありがとう\",\n",
    "            \"zh\": \"谢谢\"\n",
    "        },\n",
    "        \"please\": {\n",
    "            \"es\": \"por favor\",\n",
    "            \"fr\": \"s'il vous plaît\",\n",
    "            \"de\": \"bitte\",\n",
    "            \"it\": \"per favore\",\n",
    "            \"ja\": \"お願いします\",\n",
    "            \"zh\": \"请\"\n",
    "        },\n",
    "        \"how are you\": {\n",
    "            \"es\": \"¿cómo estás?\",\n",
    "            \"fr\": \"comment allez-vous?\",\n",
    "            \"de\": \"wie geht es dir?\",\n",
    "            \"it\": \"come stai?\",\n",
    "            \"ja\": \"お元気ですか？\",\n",
    "            \"zh\": \"你好吗？\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    async def list_languages(self) -> str:\n",
    "        \"\"\"Return a list of languages supported by the translation service.\"\"\"\n",
    "        languages = list(self._supported_languages.keys())\n",
    "        return f\"Supported languages: {', '.join(languages)}\"\n",
    "    \n",
    "\n",
    "    async def translate(\n",
    "        self, \n",
    "        text: Annotated[str, \"The English text to translate.\"],\n",
    "        target_language: Annotated[str, \"The language to translate to.\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Translate the given English text to the specified target language.\"\"\"\n",
    "        # Convert to lowercase for matching\n",
    "        text_lower = text.lower()\n",
    "        language_lower = target_language.lower()\n",
    "        \n",
    "        # Check if the target language is supported\n",
    "        if language_lower not in self._supported_languages:\n",
    "            return f\"Sorry, translation to {target_language} is not supported. Use list_languages() to see supported languages.\"\n",
    "        \n",
    "        # Get the language code\n",
    "        lang_code = self._supported_languages[language_lower]\n",
    "        \n",
    "        # Check if we have a translation for this phrase\n",
    "        for phrase, translations in self._translations.items():\n",
    "            if phrase in text_lower:\n",
    "                if lang_code in translations:\n",
    "                    # Replace the phrase with its translation\n",
    "                    translated = text.lower().replace(phrase, translations[lang_code])\n",
    "                    return f\"Translation to {target_language}: {translated}\"\n",
    "        \n",
    "        # For phrases we don't have stored, we'll simulate a generic response\n",
    "        return f\"Translation to {target_language} would normally be provided through an external API.\"\n",
    "    \n",
    "\n",
    "    async def detect_language(self, text: Annotated[str, \"The text to analyze.\"]) -> str:\n",
    "        \"\"\"Detect the likely language of the provided text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Simple detection based on known translations\n",
    "        for phrase, translations in self._translations.items():\n",
    "            for lang_code, translated_phrase in translations.items():\n",
    "                if translated_phrase in text_lower:\n",
    "                    # Get the language name from the code\n",
    "                    language = next(name for name, code in self._supported_languages.items() if code == lang_code)\n",
    "                    return f\"Detected language: {language.capitalize()}\"\n",
    "        \n",
    "        # Default response if no match found\n",
    "        return \"Language detection would normally use detailed analysis through an external API.\"\n",
    "\n",
    "tools = TranslationTool()\n",
    "\n",
    "# Create a language assistant\n",
    "language_agent = client.create_agent(\n",
    "    name=\"LanguageAssistant\",\n",
    "    instructions=\"\"\"You are a helpful language assistant that can help users with translations.\n",
    "    Use the available functions to provide translations and language information.\n",
    "    \n",
    "    When answering questions:\n",
    "    1. If a user wants to know what languages are supported, use the list_languages function\n",
    "    2. If a user wants a translation, use the translate function\n",
    "    3. If a user provides text in a foreign language, try to identify it with detect_language\n",
    "    4. Provide cultural context when relevant to the translation\n",
    "    \"\"\",\n",
    "    tools = [tools.list_languages, tools.translate, tools.detect_language]\n",
    ")\n",
    "\n",
    "thread = language_agent.get_new_thread()\n",
    "    \n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What languages can you translate to?\",\n",
    "    \"How do I say 'thank you' in French?\",\n",
    "    \"Can you detect what language this is: 'Grazie mille'?\"\n",
    "]\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nUser: {question}\")\n",
    "    response = await language_agent.run(question, thread=thread)\n",
    "    print(f\"Language Assistant: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf16f2",
   "metadata": {},
   "source": [
    "### TODO4 - do weather information as a plugin instead of translation service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72766f25",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "  <summary>Click to see solution</summary>\n",
    "  \n",
    "  ```python\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "class TranslationTool:\n",
    "    \"\"\"A tool that simulates a language translation service.\"\"\"\n",
    "    \n",
    "    # Dictionary of supported languages and their codes\n",
    "    _supported_languages = {\n",
    "        \"english\": \"en\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"french\": \"fr\",\n",
    "        \"german\": \"de\",\n",
    "        \"italian\": \"it\",\n",
    "        \"japanese\": \"ja\",\n",
    "        \"chinese\": \"zh\",\n",
    "    }\n",
    "    \n",
    "    # Simple translation dictionary for common phrases (in a real plugin, this would use an API)\n",
    "    _translations = {\n",
    "        \"hello\": {\n",
    "            \"es\": \"hola\",\n",
    "            \"fr\": \"bonjour\",\n",
    "            \"de\": \"hallo\",\n",
    "            \"it\": \"ciao\",\n",
    "            \"ja\": \"こんにちは\",\n",
    "            \"zh\": \"你好\"\n",
    "        },\n",
    "        \"goodbye\": {\n",
    "            \"es\": \"adiós\",\n",
    "            \"fr\": \"au revoir\",\n",
    "            \"de\": \"auf wiedersehen\",\n",
    "            \"it\": \"arrivederci\",\n",
    "            \"ja\": \"さようなら\",\n",
    "            \"zh\": \"再见\"\n",
    "        },\n",
    "        \"thank you\": {\n",
    "            \"es\": \"gracias\",\n",
    "            \"fr\": \"merci\",\n",
    "            \"de\": \"danke\",\n",
    "            \"it\": \"grazie\",\n",
    "            \"ja\": \"ありがとう\",\n",
    "            \"zh\": \"谢谢\"\n",
    "        },\n",
    "        \"please\": {\n",
    "            \"es\": \"por favor\",\n",
    "            \"fr\": \"s'il vous plaît\",\n",
    "            \"de\": \"bitte\",\n",
    "            \"it\": \"per favore\",\n",
    "            \"ja\": \"お願いします\",\n",
    "            \"zh\": \"请\"\n",
    "        },\n",
    "        \"how are you\": {\n",
    "            \"es\": \"¿cómo estás?\",\n",
    "            \"fr\": \"comment allez-vous?\",\n",
    "            \"de\": \"wie geht es dir?\",\n",
    "            \"it\": \"come stai?\",\n",
    "            \"ja\": \"お元気ですか？\",\n",
    "            \"zh\": \"你好吗？\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    async def list_languages(self) -> str:\n",
    "        \"\"\"Return a list of languages supported by the translation service.\"\"\"\n",
    "        languages = list(self._supported_languages.keys())\n",
    "        return f\"Supported languages: {', '.join(languages)}\"\n",
    "    \n",
    "\n",
    "    async def translate(\n",
    "        self, \n",
    "        text: Annotated[str, \"The English text to translate.\"],\n",
    "        target_language: Annotated[str, \"The language to translate to.\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Translate the given English text to the specified target language.\"\"\"\n",
    "        # Convert to lowercase for matching\n",
    "        text_lower = text.lower()\n",
    "        language_lower = target_language.lower()\n",
    "        \n",
    "        # Check if the target language is supported\n",
    "        if language_lower not in self._supported_languages:\n",
    "            return f\"Sorry, translation to {target_language} is not supported. Use list_languages() to see supported languages.\"\n",
    "        \n",
    "        # Get the language code\n",
    "        lang_code = self._supported_languages[language_lower]\n",
    "        \n",
    "        # Check if we have a translation for this phrase\n",
    "        for phrase, translations in self._translations.items():\n",
    "            if phrase in text_lower:\n",
    "                if lang_code in translations:\n",
    "                    # Replace the phrase with its translation\n",
    "                    translated = text.lower().replace(phrase, translations[lang_code])\n",
    "                    return f\"Translation to {target_language}: {translated}\"\n",
    "        \n",
    "        # For phrases we don't have stored, we'll simulate a generic response\n",
    "        return f\"Translation to {target_language} would normally be provided through an external API.\"\n",
    "    \n",
    "\n",
    "    async def detect_language(self, text: Annotated[str, \"The text to analyze.\"]) -> str:\n",
    "        \"\"\"Detect the likely language of the provided text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Simple detection based on known translations\n",
    "        for phrase, translations in self._translations.items():\n",
    "            for lang_code, translated_phrase in translations.items():\n",
    "                if translated_phrase in text_lower:\n",
    "                    # Get the language name from the code\n",
    "                    language = next(name for name, code in self._supported_languages.items() if code == lang_code)\n",
    "                    return f\"Detected language: {language.capitalize()}\"\n",
    "        \n",
    "        # Default response if no match found\n",
    "        return \"Language detection would normally use detailed analysis through an external API.\"\n",
    "\n",
    "tools = TranslationTool()\n",
    "\n",
    "# Create a language assistant\n",
    "language_agent = client.create_agent(\n",
    "    name=\"LanguageAssistant\",\n",
    "    instructions=\"\"\"You are a helpful language assistant that can help users with translations.\n",
    "    Use the available functions to provide translations and language information.\n",
    "    \n",
    "    When answering questions:\n",
    "    1. If a user wants to know what languages are supported, use the list_languages function\n",
    "    2. If a user wants a translation, use the translate function\n",
    "    3. If a user provides text in a foreign language, try to identify it with detect_language\n",
    "    4. Provide cultural context when relevant to the translation\n",
    "    \"\"\",\n",
    "    tools = [tools.list_languages, tools.translate, tools.detect_language]\n",
    ")\n",
    "\n",
    "thread = language_agent.get_new_thread()\n",
    "    \n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What languages can you translate to?\",\n",
    "    \"How do I say 'thank you' in French?\",\n",
    "    \"Can you detect what language this is: 'Grazie mille'?\"\n",
    "]\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nUser: {question}\")\n",
    "    response = await language_agent.run(question, thread=thread)\n",
    "    print(f\"Language Assistant: {response.text}\")\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maf-workshop",
   "language": "python",
   "name": "maf-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
